{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'lmadatagen' from '/Users/SophusOlsen/Desktop/lmadatagen/lmadatagen/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lmadatagen as ldg\n",
    "print(ldg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ldg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-de577e5a9d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpath_to_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./json/partial/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mjson_util\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLMAJSONUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_indeces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the video chunks as a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ldg' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Fetch the raw video chunks stored as .json files \n",
    "    from the disc. We can use cached data if they files\n",
    "    have been previously loaded.\n",
    "'''\n",
    "\n",
    "ret_from_disc = False\n",
    "path_to_json = './json/partial/'\n",
    "\n",
    "json_util = ldg.LMAJSONUtil(ldg.joint_keys, ldg.joint_indeces, ldg.meta_keys)\n",
    "\n",
    "# Load the video chunks as a list.\n",
    "segments = json_util.get_video_segments(\n",
    "    path_to_json,\n",
    "    not ret_from_disc,\n",
    "    ret_from_disc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Compute and extract motion features (based on LMA) from the motion\n",
    "    data acquired through openpose. Various hyperparameters can be setup\n",
    "    before extraction.\n",
    "    \n",
    "    We can setup hyperparameters for each available feature. The features are:\n",
    "    [0] weight\n",
    "    [1] time\n",
    "    [2] space\n",
    "    [3] flow\n",
    "    [4] shape\n",
    "    \n",
    "    The hyperparameter is a LIST containig a 3D-tuple with the following meanings:\n",
    "    \n",
    "    TUPLE = (feature, effector, weights)\n",
    "    LIST = [TUPLE0 ... TUPLE4]\n",
    "    \n",
    "    The LIST does not need to contain exactly 5 values, but it cannot exceed this limit.\n",
    "    An effector is joint that is included in the computation of the feature. \n",
    "    The weights are a list of values (any numbers) corresponding to how important the\n",
    "    correspoding effector is. \n",
    "    \n",
    "'''\n",
    "\n",
    "# Hyperparameter for feature computation\n",
    "effectors_weights_ = [\n",
    "    ('time', ['head', 'leftWrist', 'rightWrist'], [0.1, 0.45, 0.45]),\n",
    "    ('weight', None, np.ones((len(ldg.joint_keys), ))),\n",
    "]\n",
    "\n",
    "gestures_per_batch_ = 7\n",
    "\n",
    "# Setup the parameters (static function call)\n",
    "ldg.LMARunner.set_lma_hyperparams(\n",
    "    gestures_per_batch=gestures_per_batch_,\n",
    "    effectors_weights=effectors_weights_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the motion features by passing in the video\n",
    "# segments we retrieved above\n",
    "runner = ldg.LMARunner(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the features as a pandas \"DataFrame\"\n",
    "motion_features = runner.dataframe()\n",
    "print(motion_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def process_motion_features(train, test):\n",
    "    features = ['weight', 'time', 'space', 'flow', 'shape']\n",
    "    \n",
    "    cs = MinMaxScaler()\n",
    "    trainX = cs.fit_transform(train[features])\n",
    "    testX = cs.transform(test[features])\n",
    "    return (trainX, testX)\n",
    "    \n",
    "\n",
    "(train, test) = train_test_split(motion_features, test_size=0.2, random_state=42)\n",
    "trainX, testX = process_motion_features(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_step(x, a):\n",
    "    boolean_arr = np.zeros_like(x).astype(np.int32)\n",
    "    for col, predicate in enumerate(a):\n",
    "        boolean_arr[x[:, col] >= predicate, col] = 1\n",
    "        \n",
    "    return boolean_arr\n",
    "\n",
    "def action_effort(effort_features, thresholds):\n",
    "    binary_encoding = np_step(effort_features, zip(thresholds)) \n",
    "    decimal_encoding = binary_encoding.dot(\n",
    "        1 << np.arange(binary_encoding.shape[-1] - 1, -1, -1)\n",
    "    ).astype(np.int32)\n",
    "    return decimal_encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = np.log10(np.array(motion_features[['weight', 'time', 'space']]))\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "t1 = np.median(X[:, 0])\n",
    "t2 = np.median(X[:, 1])\n",
    "t3 = np.median(X[:, 2])\n",
    "ts = [t1, t2, t3]\n",
    "\n",
    "targets = action_effort(X, ts)\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "X_2 = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters = len(set(targets))\n",
    "\n",
    "kmeans = KMeans(n_clusters=clusters)\n",
    "kmeans.fit(X_2)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "fig = plt.figure(0, figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.scatter(X_2[:, 0], X_2[:, 1], c=targets)\n",
    "ax2.scatter(X_2[:, 0], X_2[:, 1], c=labels)\n",
    "ax2.scatter(centers[:, 0], centers[:, 1], c='k', s=200, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "\n",
    "som = MiniSom(7, 7, 3, sigma=4, learning_rate=0.1)\n",
    "\n",
    "print(\"Training...\")\n",
    "som.train_random(X, 20000, verbose=True)  # random training\n",
    "print(\"\\n...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for x, t in zip(X, targets):\n",
    "    w = som.winner(x)\n",
    "    plt.text(w[0]+.5,  w[1]+.5, str(t),\n",
    "              color=plt.cm.rainbow(t / 10.), fontdict={'weight': 'bold',  'size': 11})\n",
    "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
