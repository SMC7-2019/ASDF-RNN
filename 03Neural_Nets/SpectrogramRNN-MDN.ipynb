{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dwoodw19/miniconda3/envs/ML_ENV/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing the required packages\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import mdn\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Activation, LSTM, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale, minmax_scale, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next few boxes are for trying to check if GPUs are availible\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data stored in \"SMC_Dataset1/classical\" and \"SMC_Dataset1/json\"\n",
    "PATH = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "SpectrogramPath = PATH+'/SMC_dataset1/Spectrograms1024.csv'\n",
    "MotionPath = PATH+'/SMC_dataset1/motion_features9x5.csv'\n",
    "\n",
    "#Load Motion features\n",
    "MotionFeat = pd.read_csv(MotionPath, sep=',')\n",
    "MotionFeat = np.array(MotionFeat).reshape(1201, 9, 5)\n",
    "\n",
    "#Load Motion features\n",
    "Spectro = pd.read_csv(SpectrogramPath, sep=',' ,header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.41337505e+00 1.82696726e+01 2.37263817e-01 1.63819923e+03\n",
      "  1.92984207e+02]\n",
      " [1.85186981e+00 1.08041170e+01 4.29906073e-01 9.57515102e+02\n",
      "  1.82835435e+02]\n",
      " [5.49710570e+00 1.54986648e+01 1.46385572e-01 1.35782101e+03\n",
      "  6.48934681e+01]\n",
      " [5.09279455e+00 9.92993989e+00 3.69880296e-01 7.98039705e+02\n",
      "  1.39725010e+02]\n",
      " [3.91515423e+00 1.33587920e+01 9.96250386e-02 1.10158216e+03\n",
      "  1.56554556e+02]\n",
      " [1.10408430e+01 2.82637538e+01 1.15342907e-01 1.93086098e+03\n",
      "  7.19054420e+01]\n",
      " [5.01365441e+00 3.10260902e+01 1.90316688e-01 1.91160609e+03\n",
      "  6.07648309e+01]\n",
      " [3.24677907e+00 8.23084741e+00 3.13328877e-01 7.84251946e+02\n",
      "  2.72751723e+02]\n",
      " [1.54174314e+00 9.68600089e+00 7.10933205e-01 8.65627047e+02\n",
      "  7.15255468e+01]]\n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling/Normalisation of Data \n",
    "for i in range(1201):\n",
    "    MotionFeat[i] = minmax_scale(MotionFeat[i],  feature_range=(0, 1), axis=0, copy=False)\n",
    "    \n",
    "\n",
    "#Select 20% of data for validation set\n",
    "train_x, validate_x, train_y, validate_y = train_test_split(MotionFeat, Spectro, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: 10260\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "batch_size=8\n",
    "N_MIXES = 10  # number of mixture components\n",
    "OUTPUT_DIMS = 1024  # number of real-values predicted by each mixture component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MDN.call of <mdn.MDN object at 0x7f7fb1412d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MDN.call of <mdn.MDN object at 0x7f7fb1412d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MDN.call of <mdn.MDN object at 0x7f7fb1412d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MDN.call of <mdn.MDN object at 0x7f7fb1412d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (8, 9, 512)               1060864   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (8, 1024)                 6295552   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (8, 2048)                 2099200   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (8, 2048)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (8, 4096)                 8392704   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (8, 4096)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (8, 2048)                 8390656   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (8, 2048)                 0         \n",
      "_________________________________________________________________\n",
      "mdn_2 (MDN)                  (8, 20490)                41984010  \n",
      "=================================================================\n",
      "Total params: 68,222,986\n",
      "Trainable params: 68,222,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input to model is 5 vectors of 7 features\n",
    "model.add(LSTM(512, activation = 'sigmoid', return_sequences=True, batch_input_shape=(batch_size, 9, 5)))\n",
    "model.add(LSTM(1024, activation = 'sigmoid', return_sequences=False))\n",
    "model.add(Dense(2048, activation = 'sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2048, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(mdn.MDN(OUTPUT_DIMS, N_MIXES))\n",
    "model.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMS,N_MIXES), optimizer=RMSprop(learning_rate=0.0001, rho=0.9))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 426.02626, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 426.02626 to 310.51692, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 310.51692 to 293.64486, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 293.64486\n",
      "\n",
      "Epoch 00005: val_loss improved from 293.64486 to 201.39999, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 201.39999\n",
      "\n",
      "Epoch 00007: val_loss improved from 201.39999 to 95.99783, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 95.99783\n",
      "\n",
      "Epoch 00009: val_loss improved from 95.99783 to 51.26494, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 51.26494 to 21.18035, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 21.18035\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 21.18035\n",
      "\n",
      "Epoch 00013: val_loss improved from 21.18035 to -37.68599, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from -37.68599 to -139.09880, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from -139.09880 to -210.90326, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -210.90326\n",
      "\n",
      "Epoch 00017: val_loss improved from -210.90326 to -264.50135, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from -264.50135 to -300.71035, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from -300.71035 to -333.76126, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -333.76126\n",
      "\n",
      "Epoch 00021: val_loss improved from -333.76126 to -348.31497, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from -348.31497 to -361.08745, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from -361.08745 to -377.72680, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from -377.72680 to -378.71745, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -378.71745\n",
      "\n",
      "Epoch 00026: val_loss improved from -378.71745 to -378.92744, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from -378.92744 to -415.52733, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from -415.52733 to -434.79020, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -434.79020\n",
      "\n",
      "Epoch 00030: val_loss improved from -434.79020 to -445.85031, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from -445.85031 to -447.65905, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from -447.65905 to -478.16709, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -478.16709\n",
      "\n",
      "Epoch 00034: val_loss improved from -478.16709 to -479.83510, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -479.83510\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -479.83510\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -479.83510\n",
      "\n",
      "Epoch 00038: val_loss improved from -479.83510 to -484.75613, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from -484.75613 to -532.33247, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -532.33247\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -532.33247\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -532.33247\n",
      "\n",
      "Epoch 00043: val_loss improved from -532.33247 to -543.86869, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -543.86869\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -543.86869\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -543.86869\n",
      "\n",
      "Epoch 00047: val_loss improved from -543.86869 to -553.95580, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -553.95580\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -553.95580\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -553.95580\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -553.95580\n",
      "\n",
      "Epoch 00052: val_loss improved from -553.95580 to -559.88235, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from -559.88235 to -574.22055, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -574.22055\n",
      "\n",
      "Epoch 00061: val_loss improved from -574.22055 to -575.16344, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -575.16344\n",
      "\n",
      "Epoch 00063: val_loss did not improve from -575.16344\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -575.16344\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -575.16344\n",
      "\n",
      "Epoch 00066: val_loss did not improve from -575.16344\n",
      "\n",
      "Epoch 00067: val_loss improved from -575.16344 to -584.92828, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -584.92828\n",
      "\n",
      "Epoch 00069: val_loss did not improve from -584.92828\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -584.92828\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -584.92828\n",
      "\n",
      "Epoch 00072: val_loss improved from -584.92828 to -606.42563, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00075: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00078: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00081: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00082: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00083: val_loss did not improve from -606.42563\n",
      "\n",
      "Epoch 00084: val_loss improved from -606.42563 to -608.80008, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from -608.80008 to -608.98804, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from -608.98804 to -617.61012, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00087: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00088: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00089: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00090: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00091: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00092: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00093: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00094: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00095: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -617.61012\n",
      "\n",
      "Epoch 00097: val_loss improved from -617.61012 to -621.67988, saving model to MDN/model30Nmix.hdf5\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -621.67988\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -621.67988\n",
      "\n",
      "Epoch 00100: val_loss improved from -621.67988 to -629.43725, saving model to MDN/model30Nmix.hdf5\n"
     ]
    }
   ],
   "source": [
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "filepath=\"MDN/Model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint, csv_logger]\n",
    "\n",
    "history = model.fit(train_x, train_y, batch_size=batch_size, epochs=100, validation_data=(validate_x, validate_y), callbacks=callbacks_list, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
