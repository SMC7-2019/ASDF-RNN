{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Importing the required \n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import mdn\n",
    "import IPython.display as ipd\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.layers import Embedding, Dense, Activation, LSTM, Dropout, Flatten\n",
    "#from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#from tensorflow.keras.models import Model, load_model, model_from_json\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from librosa.output import write_wav \n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%aimport SMCutils\n",
    "su = SMCutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load input data \n",
    "PATH = os.getcwd()\n",
    "MotionPath = PATH+'/SMC_dataset1/motion_features9x5.csv'\n",
    "MotionFeat = np.array(pd.read_csv(MotionPath, sep=','))\n",
    "\n",
    "#Reshape into the correct format\n",
    "MotionFeat = np.reshape(MotionFeat, (-1, 9, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MotionFeat.shape\n",
    "int(len(MotionFeat)/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MDN.call of <mdn.MDN object at 0x7fde75967b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MDN.call of <mdn.MDN object at 0x7fde75967b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MDN.call of <mdn.MDN object at 0x7fde75967b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MDN.call of <mdn.MDN object at 0x7fde75967b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Load Model\n",
    "N_MIXES = 10  # number of mixture components\n",
    "OUTPUT_DIMS = 1024  # number of real-values predicted by each mixture component\n",
    "\n",
    "model = load_model('MDN/1000Epochs.hdf5', custom_objects={'MDN': mdn.MDN, 'mdn_loss_func': mdn.get_mixture_loss_func(OUTPUT_DIMS,N_MIXES)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 9, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MotionFeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predict Distributions \n",
    "Results = np.zeros(shape=(120,8,1024))\n",
    "\n",
    "for i in range(15):\n",
    "    IndexStart = i*8\n",
    "    IndexEnd = IndexStart+8\n",
    "    Predicted = model.predict(MotionFeat[IndexStart:IndexEnd, :, :])\n",
    "    \n",
    "    #Sample Distributions\n",
    "    y_sample = np.apply_along_axis(mdn.sample_from_output, 1, Predicted, 1024, N_MIXES, temp=1)\n",
    "    y_sample = np.squeeze(y_sample)\n",
    "    \n",
    "    Results[i, :, :] = y_sample\n",
    "    IndexStart += 8\n",
    "    \n",
    "np.save('Results/120Result', Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 8, 1024)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 1024) (1, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Send Results through decoder\n",
    "\n",
    "ltsm_name = 'Results/120Result.npy'\n",
    "x = np.load(ltsm_name)\n",
    "element = np.random.randint(0,len(x))\n",
    "x = np.reshape(x, (-1, 1024))\n",
    "inputdata = x[1,:]\n",
    "inputdata = np.reshape(inputdata, (1,-1))\n",
    "print(x.shape, inputdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name    = 'lstm/20kconv.json'\n",
    "weights_name  = 'lstm/20kconv.h5'\n",
    "code_name     = 'lstm/ffff_20kconv_1024_03e_codedim1024_smallerconv.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr         = 22050\n",
    "fmin       = 20\n",
    "fmax       = sr / 2 \n",
    "n_fft      = 4096\n",
    "hop_length = 690\n",
    "n_frames   = 128*2\n",
    "n_mels     = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dim       = 1024\n",
    "learning_rate  = 0.001\n",
    "optimizer      = Adam(learning_rate=learning_rate)\n",
    "loss           = 'mse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_file = open(model_name, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "autoencoder = model_from_json(loaded_model_json)\n",
    "autoencoder.load_weights(weights_name)\n",
    "autoencoder.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_data (InputLayer)      (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 128, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 256, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 128, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 32, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              33555456  \n",
      "=================================================================\n",
      "Total params: 33,943,296\n",
      "Trainable params: 33,943,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = autoencoder.get_layer('encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32768)             33587200  \n",
      "=================================================================\n",
      "Total params: 33,587,200\n",
      "Trainable params: 33,587,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = autoencoder.get_layer('decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1024)\n"
     ]
    }
   ],
   "source": [
    "SpectrogramPath = PATH+'/SMC_dataset1/Spectrograms1024.csv'\n",
    "\n",
    "x = np.array(pd.read_csv(SpectrogramPath, sep=',' ,header=None))\n",
    "x = x[0:8,:]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsm_name = 'Results/120Result.npy'\n",
    "\n",
    "\n",
    "for i in range(int(len(x))):\n",
    "    #x = np.load(ltsm_name)\n",
    "    element = np.random.randint(0,len(x))\n",
    "    x = np.reshape(x, (-1, 1024))\n",
    "    inputdata = x[i,:]\n",
    "    inputdata = np.reshape(inputdata, (1,-1))\n",
    "    decoded_data = decoder.predict(inputdata)\n",
    "    np.save('Results/Spectrogram/{:03d}'.format(i), decoded_data)\n",
    "    mel_ae, y_ae = su.spectrogram_to_audio(decoded_data,n_mels,n_frames, sr, n_fft, hop_length, fmin, fmax)\n",
    "    write_wav('Results/wav/{:03d}.wav'.format(i),y_ae, sr, norm=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 1024) 960\n"
     ]
    }
   ],
   "source": [
    "ltsm_name = 'Results/120Result.npy'\n",
    "\n",
    "x = np.load(ltsm_name)\n",
    "x = np.reshape(x, (-1, 1024))\n",
    "print(x.shape, len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Getting mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Predicted = model.predict(train_x[IndexStart:IndexEnd, :, :])\n",
    "\n",
    "y_sample = np.apply_along_axis(mdn.sample_from_output, 1, Predicted, 1024, N_MIXES, temp=1.0)\n",
    "y_sample = np.squeeze(y_sample)\n",
    "TrueValues = np.array(validate_y.iloc[IndexStart:IndexEnd, :])\n",
    "\n",
    "Predicted = y_sample.reshape(8192, 1)\n",
    "TrueValues = TrueValues.reshape(8192, 1)\n",
    "np.save('Results/Predicted_Vector_Unquantized', Predicted)\n",
    "np.save('Results/TrueValues', TrueValues)\n",
    "\n",
    "\n",
    "#Standard absolute error\n",
    "Error = mean_absolute_error(TrueValues, Predicted)\n",
    "\n",
    "#Error with all values rounded to nearest in\n",
    "PredictedQuantized = np.rint(Predicted)\n",
    "QuantizedError = mean_absolute_error(TrueValues, PredictedQuantized)\n",
    "\n",
    "\n",
    "#Only values less than 1 are quantized \n",
    "\n",
    "for n in range(np.size(Predicted, 0)):\n",
    "    for m in range (np.size(Predicted, 1)):\n",
    "        if Predicted[n][m] < 1:\n",
    "            Predicted[n][m] = 0\n",
    "           \n",
    "\n",
    "#Predicted = Predicted.reshape(8,256)\n",
    "#np.save('Predicted_Vector_PartialQuantized', Predicted)\n",
    "PartialQuantizedError = mean_absolute_error(TrueValues, Predicted)\n",
    "\n",
    "\n",
    "print(Error, PartialQuantizedError, QuantizedError)\n",
    "np.save('Results/Predicted_Vector_Quantized', PredictedQuantized)\n",
    "np.save('Results/Predicted_Vector_PartialQuantized', Predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
